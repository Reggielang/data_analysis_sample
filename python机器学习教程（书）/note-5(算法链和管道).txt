1.在缩放数据时，我们使用了训练集中的所有数据来找到训练的方法。然后，我
们使用缩放后的训练数据来运行带交叉验证的网格搜索。对于交叉验证中的每次划分，原
始训练集的一部分被划分为训练部分，另一部分被划分为测试部分。测试部分用于度量在
训练部分上所训练的模型在新数据上的表现。但是，我们在缩放数据时已经使用过测试部
分中所包含的信息

e.g:
from sklearn.pipeline import Pipeline
pipe = Pipeline([("scaler", MinMaxScaler()), ("svm", SVC())])

pipe.fit(X_train, y_train)

2.
在网格搜索中使用管道

e.g:
param_grid = {'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],
 'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]}

grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)
grid.fit(X_train, y_train)
print("Best cross-validation accuracy: {:.2f}".format(grid.best_score_))
print("Test set score: {:.2f}".format(grid.score(X_test, y_test)))
print("Best parameters: {}".format(grid.best_params_))


3. 算法链
你可以构建一个包含特征提取、特征选择、缩放和分类的管道，总共有 4 个步骤。同
样，最后一步可以用回归或聚类代替分类。
e.g:
def fit(self, X, y):
 X_transformed = X
 for name, estimator in self.steps[:-1]:
 # 遍历除最后一步之外的所有步骤
 # 对数据进行拟合和变换
 X_transformed = estimator.fit_transform(X_transformed, y)
 # 对最后一步进行拟合
 self.steps[-1][1].fit(X_transformed, y)
 return self
使用 Pipeline 进行预测时，我们同样利用除最后一步之外的所有步骤对数据进行变换
（transform），然后对最后一步调用 predict：
In[16]:
def predict(self, X):
 X_transformed = X
 for step in self.steps[:-1]:
 # 遍历除最后一步之外的所有步骤
 # 对数据进行变换
 X_transformed = step[1].transform(X_transformed)
# 利用最后一步进行预测
return self.steps[-1][1].predict(X_transformed)


有一个很方便的函数 make_pipeline，可以为我们创建管道并根据每个步骤所属的类
为其自动命名。
from sklearn.pipeline import make_pipeline
# 标准语法
pipe_long = Pipeline([("scaler", MinMaxScaler()), ("svm", SVC(C=100))])
# 缩写语法
pipe_short = make_pipeline(MinMaxScaler(), SVC(C=100))


在管道中使用网格搜索
from sklearn.linear_model import LogisticRegression
pipe = make_pipeline(StandardScaler(), LogisticRegression())

X_train, X_test, y_train, y_test = train_test_split(
 cancer.data, cancer.target, random_state=4)
grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(X_train, y_train)

print("Logistic regression step:\n{}".format(
 grid.best_estimator_.named_steps["logisticregression"]))
（ 我 们 可 以 使 用 管 道 的 named_steps 属性来访问logisticregression 步骤）

（下面我们可以访问与每个输入特征相关的系数（权重））
print("Logistic regression coefficients:\n{}".format(
 grid.best_estimator_.named_steps["logisticregression"].coef_))

网格搜索预处理步骤与模型参数

from sklearn.datasets import load_boston
boston = load_boston()
X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target,
 random_state=0)
from sklearn.preprocessing import PolynomialFeatures
pipe = make_pipeline(
 StandardScaler(),
 PolynomialFeatures(),
 Ridge())

param_grid = {'polynomialfeatures__degree': [1, 2, 3],
 'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}

grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)
grid.fit(X_train, y_train)

print("Best parameters: {}".format(grid.best_params_))

网格搜索选择使用哪个模型
pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', SVC())])

from sklearn.ensemble import RandomForestClassifier
param_grid = [
 {'classifier': [SVC()], 'preprocessing': [StandardScaler(), None],
 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],
 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},
 {'classifier': [RandomForestClassifier(n_estimators=100)],
 'preprocessing': [None], 'classifier__max_features': [1, 2, 3]}]

X_train, X_test, y_train, y_test = train_test_split(
 cancer.data, cancer.target, random_state=0)
grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(X_train, y_train)

print("Best params:\n{}\n".format(grid.best_params_))
print("Best cross-validation score: {:.2f}".format(grid.best_score_))
print("Test-set score: {:.2f}".format(grid.score(X_test, y_test)))