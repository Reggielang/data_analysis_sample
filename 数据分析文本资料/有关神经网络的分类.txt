DNN：深度神经网络

从结构上来说，DNN和传统意义上的NN（神经网络）并无太大区别，最大的不同是层数增多了，并解决了模型可训练的问题。最重要的是随着移动互联网的普及海量数据的产生和机器计算能力的增强。

简言之，DNN比NN多了一些隐层，但这些隐层的作用是巨大的，带来的效果是非常显著和神奇的。

DNN最大的问题是只能看到预先设定的长度的数据，对于语音和语言等前后相关的时序信号的表达能力还是有限的

RNN：递归神经网络

全连接的DNN存在着一个无法解决的问题：无法对时间序列上的变化进行建模。换句话说，就是递归神经网络它的隐层不但可以接收到上一层的输入，也可以得到上一时刻当前隐层的输入。

这一个变化的重要意义就在于使得神经网络具备了历史记忆的功能，原则上它可以看到无穷长的历史信息，这非常适合于像语音语言这种具有长时相关性的任务。

CNN：卷积神经网络

卷积神经网络主要是模拟人的视觉神经系统提出来的。卷积神经网络的结构依旧包括输入层、隐藏层和输出层，其中卷积神经网络的隐含层包含卷积层、池化层和全联接层3类常见构筑。

卷积层的功能是对输入数据进行特征提取，其内部包含多个卷积核，一个卷积核覆盖的原始图像的范围叫做感受野（权值共享）。一次卷积运算(哪怕是多个卷积核)提取的特征往往是局部的，难以提取出比较全局的特征，因此需要在一层卷积基础上继续做卷积计算，这就是多层卷积。


在卷积层进行特征提取后，输出的特征图会被传递至池化层进行特征选择和信息过滤。池化层包含预设定的池化函数，其功能是将特征图中单个点的结果替换为其相邻区域的特征图统计量。通过这种池化的操作，能够一定程度上克服图像的一些旋转和局部的细微变化，从而使得特征的表达更加稳定。